{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2646a34e-a634-47ac-9fe7-73bf40ece8ae",
   "metadata": {},
   "source": [
    "# Comparing Annual Changes in Sea Surface Temperature and Polar Sea Ice Concentrations \n",
    "\n",
    "## EDS 220, Fall 2021\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc47afd0-adb0-4d5b-8903-992b7904322e",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- **Peter Menzies**, UC Santa Barbara (petermenzies@bren.ucsb.edu) <br>\n",
    "https://petermenzies.github.io/\n",
    "\n",
    "\n",
    "- **Julie Cohen**, UC Santa Barbara (jscohen@bren.ucsb.edu) <br>\n",
    "https://julietcohen.github.io/\n",
    "\n",
    "\n",
    "- **Ryan Munnikhuis**, UC Santa Barbara (Rmunnikhuis@ucsb.edu) <br>\n",
    "https://ryanmunnikhuis.github.io/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c2013-fef1-44ac-bb00-3215807cacac",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "[1. Purpose](#purpose)\n",
    "\n",
    "[2. Dataset Description](#overview)\n",
    "\n",
    "[3. Data I/O](#io)\n",
    "\n",
    "[4. Metadata Display and Basic Visualization](#display)\n",
    "\n",
    "[5. Use Case Examples](#usecases)\n",
    "\n",
    "[6. Create Binder Environment](#binder)\n",
    "\n",
    "[7. References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52c6e3-3584-48be-b500-21578b61bd72",
   "metadata": {},
   "source": [
    "<a id='purpose'></a> \n",
    "### Notebook Purpose\n",
    "\n",
    "This notebook is intended to introduce you into working with, subsetting, and visualizing oceanic and ice geodatasets. For this exercise, we'll be subsetting and visualsing sea surface temperatures (SST) from the NOAA Optimum Interpolation 1/4 Degree Daily Sea Surface Temperature (OISST) Analysis, Version 2) and sea ice concentrations (SIC) data from the Monthly Mean Hadley Centre Sea Ice and SST dataset version 1 (HadISST1) data set. \n",
    "\n",
    "At the end of the lab, we will ideally have: \n",
    "\n",
    "- A gif showing changes of sea surface temperatures over a 40-year timeframe; \n",
    "\n",
    "\n",
    "- A gif showing of changes of sea ice concentrations over a 40-year timeframe; and\n",
    "\n",
    "\n",
    "- A graph showing the trend in sea surface temperatures and sea ice concentrations over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d429260a-2c30-44da-a5af-e100a440056a",
   "metadata": {},
   "source": [
    "<a id='overview'></a> \n",
    "### Datasets\n",
    "\n",
    "In this lab, we'll be using data from two sources. \n",
    "- SST: NOAA's 1/4° Daily Optimum Interpolation Sea Surface Temperature (OISST) version 2, or OISSTv2\n",
    "- SIC: Monthly Mean Hadley Centre Sea Ice and SST dataset version 1 (HadISST1)\n",
    "\n",
    "Data Google Drive: https://drive.google.com/drive/folders/1bdVrH6EB0JAjreb0xAbcb6Nps5oyW2eW?usp=sharing\n",
    "\n",
    "A description of each dataset is given below: \n",
    "\n",
    "### Sea Surface Temperature Data \n",
    "\n",
    "The NOAA 1/4° daily Optimum Interpolation Sea Surface Temperature (daily OISST) Climate Data Record (CDR) provides complete ocean temperature fields constructed by combining bias-adjusted observations from different platforms (satellites, ships, buoys) on a regular global grid, with gaps filled in by interpolation. The main input source is satellite data from the Advanced Very High-Resolution Radiometer (AVHRR), which provides high temporal-spatial coverage from late 1981 to–present. \n",
    "This dataset is stored as NetCDF files (.nc files) that include latitude and longitude coordinates, temperatures, and dates.\n",
    "\n",
    "Data source and metadata: NOAA National Centers for Environemntal Information https://www.ncei.noaa.gov/metadata/geoportal/rest/metadata/item/gov.noaa.ncdc:C00844/html\n",
    "\n",
    "NOAA Sea Surface Temperature Optimum Interpolation methods: https://www.ncei.noaa.gov/products/climate-data-records/sea-surface-temperature-optimum-interpolation\n",
    "\n",
    "\n",
    "### Sea Ice Concentration \n",
    "\n",
    "The Monthly Mean Hadley Centre Sea Ice and SST dataset version 1 (HadISST1) is one half of the merged Hadley-OI sea surface temperature (SST) and sea ice concentration (SIC) dataset. The merged product provides monthly global mean sea surface temperature and sea ice concentration data from 1870 to the present. The merging procedure was designed to take full advantage of the higher-resolution SST information found in version 2 of the NOAA weekly optimum interpolation (OI) SST analysis, the other half of the merged dataset. The combined dataset blends historical SST and modern SST observations from ships, buoys, drifters, and sea ice observations, partly from historical ship- and air-borne and partly from satellite data.This dataset is stored as NetCDF files (.nc files) that include latitude and longitude coordinates, temperatures, and dates.\n",
    "\n",
    "Data source and metadata: UCAR/NCAR - DASH Repository\n",
    "https://dashrepo.ucar.edu/dataset/158_asphilli.html\n",
    "\n",
    "Journal of Climate article explaining why the datsets were merged: https://journals.ametsoc.org/view/journals/clim/21/19/2008jcli2292.1.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deafaa9",
   "metadata": {},
   "source": [
    "## Dataset Input/Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae802a40",
   "metadata": {},
   "source": [
    "### Configure Environment\n",
    "\n",
    "We will be using xarray, rasterio, pandas, matplotlib, rioxarray, imaegio, and glob Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24baba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure Python Environment\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "import pandas as pd \n",
    "from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray\n",
    "import imageio\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d80caa0",
   "metadata": {},
   "source": [
    "### Dataset Parameters \n",
    "\n",
    "We have preloaded subsetted data into binder to avoid binder size conflicts and to minimize time needed downloading data. We'll look at a 20 year timeframe for both sea surface temperatures and sea ice concentrations. Since we've already (briefly) gone over how to visualize SST in our last presentation, we'll just show you the code that and walk you through visualizing sea ice data.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66829ab5",
   "metadata": {},
   "source": [
    "### Use Case Examples \n",
    "\n",
    "While static maps are useful for oberserving conditons at a single point in time (or an average of time span), it can sometimes be helpful to visual the change in geospatial data from year to year. This exercise is intended to provide you with multiple examples of how to animate a timeseries. In addition, this lab will also show you one method to plot two datasets on the same graph.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30c58af",
   "metadata": {},
   "source": [
    "## Part One: Sea Surface Temperature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd71dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example commands to open a single NetCDF file and view the metadata\n",
    "\n",
    "# use xarray to load in the datafile\n",
    "data_example = xr.open_dataset('Data/avhrr-only-v2.19810901.nc')\n",
    "# use head() to view the metadata associated with this file\n",
    "data_example.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc4f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of years that data were collected to read in .nc files and to title maps later on\n",
    "years = range(1981, 2022)\n",
    "\n",
    "# Empty list to populate with tif file names\n",
    "images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dee021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to read in datasets and and export as rasterized tiffs\n",
    "for i in years:\n",
    "    \n",
    "    dataset = 'Data/oisst-avhrr-v02r01.' + str(i) + '1017.nc'\n",
    "    \n",
    "    nc = xr.open_dataset(dataset)\n",
    "    \n",
    "    nc_projected = nc.rio.write_crs(4326, inplace=True)\n",
    "    \n",
    "    sst = nc_projected[\"sst\"].rio.set_spatial_dims('lon', 'lat')\n",
    "    \n",
    "    sst = sst.rename({'lat':'latitude', 'lon':'longitude'})\n",
    "    \n",
    "    sst['time'] = pd.to_datetime(sst['time'], format='%Y%m%d')\n",
    "    \n",
    "    sst = sst.squeeze()\n",
    "    \n",
    "    filename = 'Data/noaa_sst_' + str(i) + '.tif'\n",
    "    \n",
    "    sst.rio.to_raster(filename)\n",
    "    \n",
    "    images.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b234ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to render the tiffs we exported\n",
    "def raster_show(raster):\n",
    "    \n",
    "    open_rast = rio.open(raster)\n",
    "    \n",
    "    plt.figure(figsize=(10,10), dpi=150)\n",
    "    \n",
    "    plt.imshow(open_rast.read(1),\n",
    "               origin='lower',\n",
    "               cmap='plasma',\n",
    "               extent=[-180, 180, -90, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc97718",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_show('Data/noaa_sst_1981.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee81444",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_show('Data/noaa_sst_2021.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "png_rasters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c399dce",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Loop to export as png and create list of png file names\n",
    " for i in range(0, 41):\n",
    "    raster_show(images[i])\n",
    "    png = images[i] + '.png'\n",
    "    plt.title(years[i])\n",
    "    plt.savefig(png)\n",
    "    png_rasters.append(png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d902452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created composite gif from pngs\n",
    "png_imageio = []\n",
    "\n",
    "for filename in png_rasters:\n",
    "    png_imageio.append(imageio.imread(filename))\n",
    "imageio.mimsave('Data/sst_81_21.gif', png_imageio, **{'duration':0.4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d5cb75-cb54-4708-8b88-459cae2ca17d",
   "metadata": {},
   "source": [
    "## Part Two: Sea Ice Concentrations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6c557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ice = xr.open_dataset(\"Data/MODEL.ICE.HAD187001-198110.OI198111-202109.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e24df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice = ds_ice.rio.write_crs(4326, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf28ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_time = pd.DataFrame(columns=['year', 'ice_conc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9a13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_year = []\n",
    "\n",
    "ice_conc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_time['year'] = ice_year\n",
    "ice_time['ice_conc'] = ice_conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df921fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207d5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(ice_time['year'], ice_time['ice_conc'])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Ice concentration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96ed84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 40):\n",
    "    \n",
    "    ice_i = float(ice['SEAICE'][1341 + (12 * i)].mean())\n",
    "\n",
    "    year_i = 1981 + i\n",
    "\n",
    "    ice_year.append(year_i)\n",
    "\n",
    "    ice_conc.append(ice_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b0d5a6",
   "metadata": {},
   "source": [
    "## Part Three: Comparing Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86d17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62354cdf-609f-487d-be51-9ea306997a69",
   "metadata": {},
   "source": [
    "<a id='usecases'></a> \n",
    "### Use Case Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b04a9-b2bb-40ed-bb8c-9c75d3494c38",
   "metadata": {},
   "source": [
    "This is the \"meat\" of the notebook, and what will take the majority of the time to present in class. This section should provide:\n",
    "1) A plain-text summary (1-2 paragraphs) of the use case example you have chosen: include the target users and audience, and potential applicability. For example, the Week 7 SST exercise might discuss how the state of the ENSO system can be important for seasonal weather forecasts/coral bleaching outlooks, then mention the typical diagnostics associated with ENSO (i.e. identification of El Nino/La Nina events).\n",
    "\n",
    "2) Markdown and code blocks demonstrating how one walks through the desired use case example. This should be similar to the labs we've done in class: you might want to demonstrate how to isolate a particularly interesting time period, then create an image showing a feature you're interested in, for example.\n",
    "\n",
    "3) A discussion of the results and how they might be extended on further analysis. For example, we are doing El Nino/La Nina composites in class; a natural extension might be to look at individual events to see what their particular impacts were. Or if there are data quality issues which impact the results, you could discuss how these might be mitigated with additional information/analysis.\n",
    "\n",
    "Just keep in mind, you'll have roughly 20 minutes for your full presentation, and that goes surprisingly quickly! Probably 2-3 diagnostics is the most you'll be able to get through (you could try practicing with your group members to get a sense of timing).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d07de0d-1e81-442a-a895-7b7fd7906385",
   "metadata": {},
   "source": [
    "<a id='binder'></a> \n",
    "### Create Binder Environment\n",
    "\n",
    "The last step is to create a Binder environment for your project, so that we don't have to spend time configuring everyone's environment each time we switch between group presentations. Instructions are below:\n",
    "\n",
    " - Assemble all of the data needed in your Github repo: Jupyter notebooks, a README file, and any datasets needed (these should be small, if included within the repo). Larger datasets should be stored on a separate server, and access codes included within the Jupyter notebook as discussed above. \n",
    " \n",
    " - Create an _environment_ file: this is a text file which contains information on the packages needed in order to execute your code. The filename should be \"environment.yml\": an example that you can use for the proper syntax is included in this template repo. To determine which packages to include, you'll probably want to start by displaying the packages loaded in your environment: you can use the command `conda list -n [environment_name]` to get a list.\n",
    " \n",
    " More information on environment files can be found here:\n",
    " https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#\n",
    "\n",
    " - Create Binder. Use http://mybinder.org to create a  URL for your notebook Binder (you will need to enter your GitHub repo URL). You can also add a Launch Binder button directly to your GitHub repo, by including the following in your README.md:\n",
    "\n",
    "```\n",
    "launch with myBinder\n",
    "[![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/<path to your repo>)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62c774b-8a7c-4f47-9c07-7f9823c48473",
   "metadata": {},
   "source": [
    "<a id='references'></a> \n",
    "### References\n",
    "\n",
    "List relevant references. Here are some additional resources on creating professional, shareable notebooks you may find useful:\n",
    "\n",
    "1. Notebook sharing guidelines from reproducible-science-curriculum: https://reproducible-science-curriculum.github.io/publication-RR-Jupyter/\n",
    "2. Guide for developing shareable notebooks by Kevin Coakley, SDSC: https://github.com/kevincoakley/sharing-jupyter-notebooks/raw/master/Jupyter-Notebooks-Sharing-Recommendations.pdf\n",
    "3. Guide for sharing notebooks by Andrea Zonca, SDSC: https://zonca.dev/2020/09/how-to-share-jupyter-notebooks.html\n",
    "4. Jupyter Notebook Best Practices: https://towardsdatascience.com/jupyter-notebook-best-practices-f430a6ba8c69\n",
    "5. Introduction to Jupyter templates nbextension: https://towardsdatascience.com/stop-copy-pasting-notebooks-embrace-jupyter-templates-6bd7b6c00b94  \n",
    "    5.1. Table of Contents (Toc2) readthedocs: https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/toc2/README.html  \n",
    "    5.2. Steps to install toc2: https://stackoverflow.com/questions/23435723/installing-ipython-notebook-table-of-contents\n",
    "6. Rule A, Birmingham A, Zuniga C, Altintas I, Huang SC, et al. (2019) Ten simple rules for writing and sharing computational analyses in Jupyter Notebooks. PLOS Computational Biology 15(7): e1007007. https://doi.org/10.1371/journal.pcbi.1007007. Supplementary materials: example notebooks (https://github.com/jupyter-guide/ten-rules-jupyter) and tutorial (https://github.com/ISMB-ECCB-2019-Tutorial-AM4/reproducible-computational-workflows)\n",
    "7. Languages supported by Jupyter kernels: https://github.com/jupyter/jupyter/wiki/Jupyter-kernels\n",
    "8. EarthCube notebooks presented at EC Annual Meeting 2020: https://www.earthcube.org/notebooks\n",
    "9. Manage your Python Virtual Environment with Conda: https://towardsdatascience.com/manage-your-python-virtual-environment-with-conda-a0d2934d5195\n",
    "10. Venv - Creation of Virtual Environments: https://docs.python.org/3/library/venv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f10df5-100c-4f4a-a1c3-bd417b524a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
